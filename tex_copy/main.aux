\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\babel@aux{brazilian}{}
\babel@aux{english}{}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Acerbi_2018}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Ghahramani_2015}
\citation{Acerbi_2018}
\citation{Guo_2016}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Summary}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Guo_2016}
\citation{Acerbi_2018}
\citation{Guo_2016}
\citation{MacKay2003}
\citation{jaynes03}
\citation{jaynes03}
\citation{Cox_1963}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Bayesian inference and learning}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Learning described as Bayesian inference}{3}{section.2.1}}
\newlabel{bayes_theorem_1}{{2.1}{4}{Learning described as Bayesian inference}{equation.2.1.1}{}}
\newlabel{marginalization_1}{{2.2}{4}{Learning described as Bayesian inference}{equation.2.1.2}{}}
\newlabel{bayes_theorem_2}{{2.3}{4}{Learning described as Bayesian inference}{equation.2.1.3}{}}
\newlabel{marginalization_2}{{2.4}{4}{Learning described as Bayesian inference}{equation.2.1.4}{}}
\citation{Robert_2001}
\citation{Robert_2001}
\newlabel{marginalizationpred}{{2.5}{5}{Learning described as Bayesian inference}{equation.2.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Decision theory}{5}{section.2.2}}
\newlabel{decision_theory_section}{{2.2}{5}{Decision theory}{section.2.2}{}}
\newlabel{generalloss}{{2.6}{5}{Decision theory}{equation.2.2.6}{}}
\citation{Bassett_2018}
\newlabel{map_definition}{{2.8}{6}{Decision theory}{equation.2.2.8}{}}
\newlabel{mle_definition}{{2.11}{6}{Decision theory}{equation.2.2.11}{}}
\citation{Betancourt_2017}
\citation{Robert_2001}
\citation{MacKay2003}
\citation{MacKay_1991}
\citation{Rasmussen_2001}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Model selection}{8}{section.2.3}}
\newlabel{modelselectionsection}{{2.3}{8}{Model selection}{section.2.3}{}}
\newlabel{marginalization_3}{{2.14}{8}{Model selection}{equation.2.3.14}{}}
\newlabel{modelselectionobjective}{{2.16}{8}{Model selection}{equation.2.3.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Approximate inference}{10}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Monte Carlo integration methods}{10}{subsection.2.4.1}}
\newlabel{ev_example}{{2.21}{10}{Monte Carlo integration methods}{equation.2.4.21}{}}
\citation{Robert_2005}
\citation{Robert_2005}
\citation{Brooks_2011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.1}Importance sampling}{11}{subsubsection.2.4.1.1}}
\newlabel{is_rewrite}{{2.23}{11}{Importance sampling}{equation.2.4.23}{}}
\newlabel{is_derivation_1}{{2.24}{11}{Importance sampling}{equation.2.4.24}{}}
\newlabel{is_derivation_2}{{2.25}{11}{Importance sampling}{equation.2.4.25}{}}
\citation{Robert_2005}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.2}Markov Chain Monte Carlo}{12}{subsubsection.2.4.1.2}}
\citation{Geyer_2011}
\newlabel{cltmc}{{2.30}{13}{Markov Chain Monte Carlo}{equation.2.4.30}{}}
\citation{Bishop_2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Laplace's approximation}{14}{subsection.2.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2.1}Remark on approximation}{15}{subsubsection.2.4.2.1}}
\citation{Andrieu_2009}
\citation{Andrieu_2010}
\citation{Sherlock_2015}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Expensive and intractable likelihoods}{16}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Pseudo-marginals}{16}{subsection.2.5.1}}
\newlabel{pseudomarginalsection}{{2.5.1}{16}{Pseudo-marginals}{subsection.2.5.1}{}}
\newlabel{ilikemargin}{{2.38}{16}{Pseudo-marginals}{equation.2.5.38}{}}
\citation{Pritchard_1999}
\citation{Beaumont_2003}
\citation{Fearnhead_2012}
\citation{Beaumont_2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Approximate Bayesian computation}{17}{subsection.2.5.2}}
\citation{Fearnhead_2012}
\citation{Tarantola_2004}
\newlabel{abclikelihood}{{2.41}{18}{Approximate Bayesian computation}{equation.2.5.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Expensive likelihoods}{18}{subsection.2.5.3}}
\citation{Rasmussen_2003}
\citation{Wang_2018_2}
\citation{Bilionis_2013}
\citation{Kandasamy_2015}
\citation{Conrad_2016}
\citation{Bliznyuk_2012}
\citation{Marzouk_2007}
\citation{Acerbi_2018}
\citation{Ghahramani_2013}
\citation{Hjort_2010}
\citation{Rasmussen06}
\citation{Rasmussen06}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Gaussian processes}{20}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Parametric and nonparametric regression}{20}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Gaussian process regression}{20}{section.3.2}}
\citation{Dudley_2002}
\citation{Shawe_Taylor_2004}
\citation{Shawe_Taylor_2004}
\citation{Kanagawa_2018}
\citation{Stuart_2010}
\newlabel{jointGP}{{3.3}{22}{Gaussian process regression}{equation.3.2.3}{}}
\newlabel{meancovGPRpure}{{3.4}{22}{Gaussian process regression}{equation.3.2.4}{}}
\newlabel{GPRasGP}{{3.5}{22}{Gaussian process regression}{equation.3.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Gaussian noise}{22}{subsection.3.2.1}}
\newlabel{jointGPnoise}{{3.6}{22}{Gaussian noise}{equation.3.2.6}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{gprex1a}{{3.1a}{23}{Subfigure 3 3.1a}{subfigure.3.1.1}{}}
\newlabel{sub@gprex1a}{{(a)}{a}{Subfigure 3 3.1a\relax }{subfigure.3.1.1}{}}
\newlabel{gprex1b}{{3.1b}{23}{Subfigure 3 3.1b}{subfigure.3.1.2}{}}
\newlabel{sub@gprex1b}{{(b)}{b}{Subfigure 3 3.1b\relax }{subfigure.3.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Gaussian process regression of $f(x) = \qopname  \relax o{sin}(\pi x)$}}{23}{figure.caption.4}}
\newlabel{gprfig}{{3.1}{23}{Gaussian process regression of $f(x) = \sin (\pi x)$}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {GP prior}}}{23}{subfigure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {GP posterior}}}{23}{subfigure.1.2}}
\newlabel{meancovGPR}{{3.7}{23}{Gaussian noise}{equation.3.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}General noise}{23}{subsection.3.2.2}}
\newlabel{generalnoise}{{3.8}{23}{General noise}{equation.3.2.8}{}}
\citation{hogben14}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Mean function}{24}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Covariance functions}{24}{section.3.3}}
\citation{Shawe_Taylor_2004}
\citation{Stein_1999}
\citation{Rasmussen06}
\citation{Chatfield_2004}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.0.1}Stationary covariance functions}{25}{subsubsection.3.3.0.1}}
\citation{CIS-4647}
\citation{Rasmussen06}
\newlabel{sqekernel}{{3.10}{26}{Stationary covariance functions}{equation.3.3.10}{}}
\newlabel{maternkernel}{{3.12}{26}{Stationary covariance functions}{equation.3.3.12}{}}
\citation{Stein_1999}
\citation{wilson2013gaussian}
\citation{wilson2013gaussian}
\citation{Rasmussen06}
\citation{hogben14}
\newlabel{spectralmixturekernel}{{3.14}{27}{Stationary covariance functions}{equation.3.3.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Derived kernels}{27}{subsection.3.3.1}}
\newlabel{scaledkernels}{{3.15}{28}{Derived kernels}{equation.3.3.15}{}}
\citation{Mohammed_2017}
\citation{Neal_1997}
\citation{Petelin_2014}
\citation{Osborne_2007}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Model selection}{29}{section.3.4}}
\newlabel{loglikelihoodGP}{{3.16}{29}{Model selection}{equation.3.4.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Computational issues}{30}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Jittering}{30}{subsection.3.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Scaling with data}{30}{subsection.3.5.2}}
\newlabel{scalinggpsession}{{3.5.2}{30}{Scaling with data}{subsection.3.5.2}{}}
\citation{Osborne_2012}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Online learning}{31}{section.3.6}}
\newlabel{onlinelearningsection}{{3.6}{31}{Online learning}{section.3.6}{}}
\newlabel{formatcholexpanded}{{3.19}{31}{Online learning}{equation.3.6.19}{}}
\citation{Ghahramani_2003}
\citation{O_Hagan_1991}
\citation{Rasmussen06}
\citation{Hennig_2012}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Bayesian Monte Carlo}{33}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{integralbmc}{{4.1}{33}{Bayesian Monte Carlo}{equation.4.0.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}GP approximation for the integrand}{33}{section.4.1}}
\newlabel{bmcrv}{{4.2}{33}{GP approximation for the integrand}{equation.4.1.2}{}}
\newlabel{evbmc}{{4.3}{33}{GP approximation for the integrand}{equation.4.1.3}{}}
\newlabel{varbmc}{{4.4}{34}{GP approximation for the integrand}{equation.4.1.4}{}}
\newlabel{evvarbmc2}{{4.5}{34}{GP approximation for the integrand}{equation.4.1.5}{}}
\newlabel{zbmcdef}{{4.6}{34}{GP approximation for the integrand}{equation.4.1.6}{}}
\newlabel{varcoef}{{4.7}{34}{GP approximation for the integrand}{equation.4.1.7}{}}
\citation{Mermin_2004}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustration of Bayesian Monte Carlo integration}}{35}{figure.caption.5}}
\newlabel{bmcfig}{{4.1}{35}{Illustration of Bayesian Monte Carlo integration}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Philosophical remark}{35}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Kernel-distribution combinations}{36}{section.4.2}}
\newlabel{kerneldistributionbmc}{{4.2}{36}{Kernel-distribution combinations}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}SQE kernel with Gaussian distributions}{36}{subsection.4.2.1}}
\newlabel{rbfasnormal}{{4.8}{36}{SQE kernel with Gaussian distributions}{equation.4.2.8}{}}
\newlabel{kpexpansion1}{{4.9}{36}{SQE kernel with Gaussian distributions}{equation.4.2.9}{}}
\newlabel{kpexpansion2}{{4.10}{36}{SQE kernel with Gaussian distributions}{equation.4.2.10}{}}
\newlabel{termsbmcgaussian}{{4.11}{37}{SQE kernel with Gaussian distributions}{equation.4.2.11}{}}
\newlabel{evvarbmcgaussian}{{4.12}{37}{SQE kernel with Gaussian distributions}{equation.4.2.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Mixture distributions}{37}{subsection.4.2.2}}
\newlabel{bmcmixtures}{{4.2.2}{37}{Mixture distributions}{subsection.4.2.2}{}}
\newlabel{bmcmixgaussians}{{4.15}{38}{Mixture distributions}{equation.4.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Tensor product kernels and diagonal-covariance Gaussian distributions}{38}{subsection.4.2.3}}
\newlabel{tensorprodbmc}{{4.2.3}{38}{Tensor product kernels and diagonal-covariance Gaussian distributions}{subsection.4.2.3}{}}
\newlabel{prodkernelz}{{4.17}{38}{Tensor product kernels and diagonal-covariance Gaussian distributions}{equation.4.2.17}{}}
\newlabel{prodkernelgamma}{{4.18}{38}{Tensor product kernels and diagonal-covariance Gaussian distributions}{equation.4.2.18}{}}
\citation{Liu_1994}
\newlabel{gausshermite}{{4.19}{39}{Tensor product kernels and diagonal-covariance Gaussian distributions}{equation.4.2.19}{}}
\citation{Epanechnikov_1969}
\citation{Ghahramani_2003}
\citation{Osborne_2012}
\citation{OHagan_1992}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Importance reweighting for Bayesian Monte Carlo}{40}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Bayesian Monte Carlo for positive integrands}{40}{section.4.3}}
\newlabel{positivebmc}{{4.3}{40}{Bayesian Monte Carlo for positive integrands}{section.4.3}{}}
\newlabel{lntranswrong}{{4.26}{40}{Bayesian Monte Carlo for positive integrands}{equation.4.3.26}{}}
\citation{Gunter_2014}
\citation{Gunter_2014}
\citation{Chai_2019}
\citation{Osborne_2012}
\newlabel{sqlinearization}{{4.28}{41}{Bayesian Monte Carlo for positive integrands}{equation.4.3.28}{}}
\newlabel{sqmomentmatched}{{4.29}{41}{Bayesian Monte Carlo for positive integrands}{equation.4.3.29}{}}
\citation{Chai_2019}
\citation{Chai_2019}
\citation{Chai_2019}
\citation{Chai_2019}
\newlabel{logmomentmatched}{{4.30}{42}{Bayesian Monte Carlo for positive integrands}{equation.4.3.30}{}}
\newlabel{taylormomentmatched}{{4.31}{42}{Bayesian Monte Carlo for positive integrands}{equation.4.3.31}{}}
\citation{Briol_2015}
\citation{Smith_1995}
\citation{Murray_2016}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Choosing evaluation points}{43}{section.4.4}}
\newlabel{optimal_bmc}{{4.33}{43}{Choosing evaluation points}{equation.4.4.33}{}}
\newlabel{sequential_bmc}{{4.35}{43}{Choosing evaluation points}{equation.4.4.35}{}}
\citation{Gunter_2014}
\citation{Chai_2019}
\citation{Kanagawa_2019}
\newlabel{us_bmc}{{4.38}{44}{Choosing evaluation points}{equation.4.4.38}{}}
\newlabel{mmlt1}{{4.41}{44}{Choosing evaluation points}{equation.4.4.41}{}}
\citation{Booker_1999}
\citation{Jones_2001}
\citation{Asher_2015}
\citation{Shahriari_2016}
\citation{Brochu_2010}
\citation{Snoek_2012}
\newlabel{mmlt2}{{4.42}{45}{Choosing evaluation points}{equation.4.4.42}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Bayesian Monte Carlo and Bayesian Optimization}{45}{section.4.5}}
\citation{Bishop_2007}
\citation{Blei_2017}
\citation{Murphy_2012}
\citation{Zhang_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Variational inference}{47}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Variational inference}{47}{section.5.1}}
\newlabel{viobjective1}{{5.2}{47}{Variational inference}{equation.5.1.2}{}}
\citation{Murphy_2012}
\citation{Hernandes-Lobato_2015}
\citation{Yingzhen_2016}
\citation{Wang_2018}
\citation{Bishop_2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}KL divergence and evidence lower bound}{48}{subsection.5.1.1}}
\newlabel{elbodef}{{5.6}{48}{KL divergence and evidence lower bound}{equation.5.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1.1}Qualitative interpretations}{49}{subsubsection.5.1.1.1}}
\newlabel{elboterm1}{{5.9}{49}{Qualitative interpretations}{equation.5.1.9}{}}
\citation{Bishop_2007}
\citation{Bishop_2007}
\citation{Bishop_2007}
\newlabel{vixep1a}{{5.1a}{50}{Subfigure 5 5.1a}{subfigure.5.1.1}{}}
\newlabel{sub@vixep1a}{{(a)}{a}{Subfigure 5 5.1a\relax }{subfigure.5.1.1}{}}
\newlabel{vixep1b}{{5.1b}{50}{Subfigure 5 5.1b}{subfigure.5.1.2}{}}
\newlabel{sub@vixep1b}{{(b)}{b}{Subfigure 5 5.1b\relax }{subfigure.5.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Difference of behavior when minimizing $D_{KL}(q||g)$ and $D_{KL}(g||q)$}}{50}{figure.caption.6}}
\newlabel{vixepfigure}{{5.1}{50}{Difference of behavior when minimizing $D_{KL}(q||g)$ and $D_{KL}(g||q)$}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$D_{KL}(q||g)$ }}}{50}{subfigure.1.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$D_{KL}(g||q)$}}}{50}{subfigure.1.2}}
\citation{Bishop_2007}
\citation{Boyd_2004}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Mean field variational inference}{51}{section.5.2}}
\newlabel{mfviexpansion}{{5.11}{51}{Mean field variational inference}{equation.5.2.11}{}}
\newlabel{mfviqj}{{5.12}{51}{Mean field variational inference}{equation.5.2.12}{}}
\citation{Blei_2017}
\citation{Hensman_2012}
\citation{Hoffman_2013}
\citation{Zhang_2019}
\citation{Zhang_2019}
\citation{Robbins_1951}
\citation{Kingma_2014}
\citation{Qian_1999}
\citation{Ruder_2016}
\newlabel{exponential_family}{{5.13}{52}{Mean field variational inference}{equation.5.2.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Generic variational inference}{52}{section.5.3}}
\citation{Wingate_2013}
\citation{Ranganath_2014}
\citation{Wingate_2013}
\citation{Ranganath_2014}
\citation{Titsias_2015}
\citation{Ruiz_2016}
\citation{Kingma_2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}REINFORCE}{53}{subsection.5.3.1}}
\newlabel{reinforce}{{5.16}{53}{REINFORCE}{equation.5.3.16}{}}
\newlabel{reinforcemc}{{5.17}{53}{REINFORCE}{equation.5.3.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Reparameterization trick}{53}{subsection.5.3.2}}
\newlabel{reparameterizationsection}{{5.3.2}{53}{Reparameterization trick}{subsection.5.3.2}{}}
\newlabel{reparamderiv1}{{5.19}{54}{Reparameterization trick}{equation.5.3.19}{}}
\newlabel{reparamderiv2}{{5.20}{54}{Reparameterization trick}{equation.5.3.20}{}}
\citation{Zhang_2019}
\citation{Bishop_1997}
\citation{Jaakkola_1998}
\citation{Gershman_2012}
\citation{Salimans_2012}
\citation{Acerbi_2018}
\citation{Arenz_2018}
\citation{Guo_2016}
\citation{Jankowiak_2019}
\citation{Miller_2016}
\citation{Miller_2016}
\newlabel{mcreparameterization}{{5.24}{55}{Reparameterization trick}{equation.5.3.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Mixtures of gaussians for variational approximations}{55}{section.5.4}}
\newlabel{mixgaussiansvi}{{5.4}{55}{Mixtures of gaussians for variational approximations}{section.5.4}{}}
\citation{Epanechnikov_1969}
\citation{Pinheiro_1996}
\citation{Smith_1995}
\citation{Murray_2016}
\newlabel{elbomixturegaussians}{{5.33}{57}{Mixtures of gaussians for variational approximations}{equation.5.4.33}{}}
\citation{Freund_1997}
\citation{Freund_1999}
\citation{Friedman_2000}
\citation{Miller_2016}
\citation{Guo_2016}
\newlabel{mcmixturegaussians}{{5.34}{58}{Mixtures of gaussians for variational approximations}{equation.5.4.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Boosting mixtures of gaussians}{58}{subsection.5.4.1}}
\newlabel{boostedvi_section}{{5.4.1}{58}{Boosting mixtures of gaussians}{subsection.5.4.1}{}}
\citation{Miller_2016}
\citation{Guo_2016}
\citation{Tong_Zhang_2003}
\citation{Guo_2016}
\citation{Guo_2016}
\newlabel{miller_objective}{{5.36}{59}{Boosting mixtures of gaussians}{equation.5.4.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Gradient boosting mixture of gaussians}{59}{subsection.5.4.2}}
\newlabel{gradboostsection}{{5.4.2}{59}{Gradient boosting mixture of gaussians}{subsection.5.4.2}{}}
\newlabel{boosting_objective_alpha}{{5.39}{59}{Gradient boosting mixture of gaussians}{equation.5.4.39}{}}
\citation{Guo_2016}
\citation{Friedman_2001}
\citation{Guo_2016}
\newlabel{boosting_objective_dalpha}{{5.40}{60}{Gradient boosting mixture of gaussians}{equation.5.4.40}{}}
\newlabel{idealklgrad}{{5.43}{60}{Gradient boosting mixture of gaussians}{equation.5.4.43}{}}
\citation{Locatelo_2018}
\citation{Locatelo_2018}
\citation{Locatelo_2018}
\citation{Guo_2016}
\citation{Acerbi_2018}
\newlabel{relbogaussian}{{5.45}{61}{Gradient boosting mixture of gaussians}{equation.5.4.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Using Bayesian Monte Carlo in Variational Inference}{61}{section.5.5}}
\newlabel{vbmc_section}{{5.5}{61}{Using Bayesian Monte Carlo in Variational Inference}{section.5.5}{}}
\newlabel{vbalgorithm}{{0}{62}{Gradient boosting mixture of gaussians}{equation.5.4.45}{}}
\@writefile{lop}{\contentsline {Algorithm}{\numberline {1}{\ignorespaces Variational boosting algorithm.\relax }}{62}{Algorithm.1}}
\newlabel{vbalgorithm}{{1}{62}{Variational boosting algorithm.\relax }{Algorithm.1}{}}
\newlabel{vbmc_rvs}{{5.46}{62}{Using Bayesian Monte Carlo in Variational Inference}{equation.5.5.46}{}}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\citation{Huber_2008}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Quadratic mean function}{64}{subsection.5.5.1}}
\newlabel{quadmeanfnsection}{{5.5.1}{64}{Quadratic mean function}{subsection.5.5.1}{}}
\citation{Petersen_2012}
\newlabel{vbmc_quadratic_mean}{{5.50}{65}{Quadratic mean function}{equation.5.5.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Remarks on acquisition functions for VBMC}{65}{subsection.5.5.2}}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2.1}Uncertainty sampling and prospective prediction}{66}{subsubsection.5.5.2.1}}
\newlabel{us_vbmc}{{5.55}{66}{Uncertainty sampling and prospective prediction}{equation.5.5.55}{}}
\newlabel{prospective_vbmc}{{5.56}{66}{Uncertainty sampling and prospective prediction}{equation.5.5.56}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Boosted Variational Bayesian Monte Carlo}{68}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Boosting Variational Bayesian Monte Carlo}{68}{section.6.1}}
\newlabel{relbo_vbmc}{{6.1}{69}{Boosting Variational Bayesian Monte Carlo}{equation.6.1.1}{}}
\newlabel{lalpha_vbmc}{{6.2}{69}{Boosting Variational Bayesian Monte Carlo}{equation.6.1.2}{}}
\@writefile{lop}{\contentsline {Algorithm}{\numberline {2}{\ignorespaces  Naive boosted variational bayesian monte carlo\relax }}{70}{Algorithm.2}}
\newlabel{naivebvbmc}{{2}{70}{Naive boosted variational bayesian monte carlo\relax }{Algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Practical issues}{70}{subsection.6.1.1}}
\citation{Guo_2016}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.1}RELBO stabilization}{71}{subsubsection.6.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.2}Output scaling}{72}{subsubsection.6.1.1.2}}
\newlabel{outputscaling}{{6.1.1.2}{72}{Output scaling}{subsubsection.6.1.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.3}Component initialization}{73}{subsubsection.6.1.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.4}Component pruning}{73}{subsubsection.6.1.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.5}Mean functions}{74}{subsubsection.6.1.1.5}}
\newlabel{meansection}{{6.1.1.5}{74}{Mean functions}{subsubsection.6.1.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.6}Periodic joint parameter updating}{75}{subsubsection.6.1.1.6}}
\newlabel{jointparameterupdating}{{6.1.1.6}{75}{Periodic joint parameter updating}{subsubsection.6.1.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.7}Other kernel functions}{75}{subsubsection.6.1.1.7}}
\citation{Paszke_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Other acquisition functions for active evaluation}{76}{subsection.6.1.2}}
\newlabel{soft_prospective_vbmc}{{6.13}{76}{Other acquisition functions for active evaluation}{equation.6.1.13}{}}
\newlabel{mmlt_vbmc}{{6.14}{76}{Other acquisition functions for active evaluation}{equation.6.1.14}{}}
\newlabel{mmltprop_vbmc}{{6.15}{76}{Other acquisition functions for active evaluation}{equation.6.1.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Implementation}{76}{section.6.2}}
\citation{Goodfellow_2016}
\citation{Goodfellow_2016}
\citation{Theano_2016}
\citation{Abadi_2015}
\citation{Paszke_2017}
\citation{Salvatier_2016}
\citation{Tran_2016}
\citation{Bingham_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Backpropagation}{77}{subsection.6.2.1}}
\newlabel{bvbmcpackexample}{{\caption@xref {bvbmcpackexample}{ on input line 218}}{78}{Implementation}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Usage of the BVBMC Python package.}}{78}{figure.caption.7}}
\newlabel{bvbmcpackexample}{{6.1}{78}{Usage of the BVBMC Python package}{figure.caption.7}{}}
\newlabel{fig11a}{{6.2a}{79}{Subfigure 6 6.2a}{subfigure.6.2.1}{}}
\newlabel{sub@fig11a}{{(a)}{a}{Subfigure 6 6.2a\relax }{subfigure.6.2.1}{}}
\newlabel{fig11b}{{6.2b}{79}{Subfigure 6 6.2b}{subfigure.6.2.2}{}}
\newlabel{sub@fig11b}{{(b)}{b}{Subfigure 6 6.2b\relax }{subfigure.6.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces True density and estimated density found by running code in Figure \ref  {bvbmcpackexample}}}{79}{figure.caption.8}}
\newlabel{bvbmcpackfigs}{{6.2}{79}{True density and estimated density found by running code in Figure \ref {bvbmcpackexample}}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {True density}}}{79}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Estimated density}}}{79}{subfigure.2.2}}
\@writefile{lop}{\contentsline {Algorithm}{\numberline {3}{\ignorespaces Boosted Variational Bayesian Monte Carlo\relax }}{80}{Algorithm.3}}
\newlabel{bvbmcalgorithm}{{3}{80}{Boosted Variational Bayesian Monte Carlo\relax }{Algorithm.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Experiments}{81}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}1-d Mixture of Gaussians}{81}{section.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces  Target distribution.\relax }}{82}{figure.caption.9}}
\newlabel{target1dmixture}{{7.1}{82}{Target distribution.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Passive evaluation}{82}{subsection.7.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.1}Influence of kernel in approximation}{82}{subsubsection.7.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.2}Influence of training routine in approximation}{83}{subsubsection.7.1.1.2}}
\newlabel{fig11a}{{7.2a}{84}{Subfigure 7 7.2a}{subfigure.7.2.1}{}}
\newlabel{sub@fig11a}{{(a)}{a}{Subfigure 7 7.2a\relax }{subfigure.7.2.1}{}}
\newlabel{fig11b}{{7.2b}{84}{Subfigure 7 7.2b}{subfigure.7.2.2}{}}
\newlabel{sub@fig11b}{{(b)}{b}{Subfigure 7 7.2b\relax }{subfigure.7.2.2}{}}
\newlabel{fig11a}{{7.2c}{84}{Subfigure 7 7.2c}{subfigure.7.2.3}{}}
\newlabel{sub@fig11a}{{(c)}{c}{Subfigure 7 7.2c\relax }{subfigure.7.2.3}{}}
\newlabel{fig11b}{{7.2d}{84}{Subfigure 7 7.2d}{subfigure.7.2.4}{}}
\newlabel{sub@fig11b}{{(d)}{d}{Subfigure 7 7.2d\relax }{subfigure.7.2.4}{}}
\newlabel{fig11a}{{7.2e}{84}{Subfigure 7 7.2e}{subfigure.7.2.5}{}}
\newlabel{sub@fig11a}{{(e)}{e}{Subfigure 7 7.2e\relax }{subfigure.7.2.5}{}}
\newlabel{fig11b}{{7.2f}{84}{Subfigure 7 7.2f}{subfigure.7.2.6}{}}
\newlabel{sub@fig11b}{{(f)}{f}{Subfigure 7 7.2f\relax }{subfigure.7.2.6}{}}
\newlabel{fig11a}{{7.2g}{84}{Subfigure 7 7.2g}{subfigure.7.2.7}{}}
\newlabel{sub@fig11a}{{(g)}{g}{Subfigure 7 7.2g\relax }{subfigure.7.2.7}{}}
\newlabel{fig11b}{{7.2h}{84}{Subfigure 7 7.2h}{subfigure.7.2.8}{}}
\newlabel{sub@fig11b}{{(h)}{h}{Subfigure 7 7.2h\relax }{subfigure.7.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Accuracy analysis for different kernels.}}{84}{figure.caption.10}}
\newlabel{kernelcomparison}{{7.2}{84}{Accuracy analysis for different kernels}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$k_{\text {PMat},1/2}$, moments.}}}{84}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$k_{\text {PMat},1/2}$, final result.}}}{84}{subfigure.2.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$k_{\text {PMat},3/2}$, moments.}}}{84}{subfigure.2.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$k_{\text {PMat},3/2}$, final result.}}}{84}{subfigure.2.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {$k_{\text {PMat},5/2}$, moments.}}}{84}{subfigure.2.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {$k_{\text {PMat},5/2}$, final result.}}}{84}{subfigure.2.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {$k_{\text {SQE}}$, moments.}}}{84}{subfigure.2.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {$k_{\text {SQE}}$, final result.}}}{84}{subfigure.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Active evaluation}{85}{subsection.7.1.2}}
\newlabel{fig11a}{{7.3a}{86}{Subfigure 7 7.3a}{subfigure.7.3.1}{}}
\newlabel{sub@fig11a}{{(a)}{a}{Subfigure 7 7.3a\relax }{subfigure.7.3.1}{}}
\newlabel{fig11b}{{7.3b}{86}{Subfigure 7 7.3b}{subfigure.7.3.2}{}}
\newlabel{sub@fig11b}{{(b)}{b}{Subfigure 7 7.3b\relax }{subfigure.7.3.2}{}}
\newlabel{fig11b}{{7.3c}{86}{Subfigure 7 7.3c}{subfigure.7.3.3}{}}
\newlabel{sub@fig11b}{{(c)}{c}{Subfigure 7 7.3c\relax }{subfigure.7.3.3}{}}
\newlabel{fig11a}{{7.3d}{86}{Subfigure 7 7.3d}{subfigure.7.3.4}{}}
\newlabel{sub@fig11a}{{(d)}{d}{Subfigure 7 7.3d\relax }{subfigure.7.3.4}{}}
\newlabel{fig11b}{{7.3e}{86}{Subfigure 7 7.3e}{subfigure.7.3.5}{}}
\newlabel{sub@fig11b}{{(e)}{e}{Subfigure 7 7.3e\relax }{subfigure.7.3.5}{}}
\newlabel{fig11b}{{7.3f}{86}{Subfigure 7 7.3f}{subfigure.7.3.6}{}}
\newlabel{sub@fig11b}{{(f)}{f}{Subfigure 7 7.3f\relax }{subfigure.7.3.6}{}}
\newlabel{fig11a}{{7.3g}{86}{Subfigure 7 7.3g}{subfigure.7.3.7}{}}
\newlabel{sub@fig11a}{{(g)}{g}{Subfigure 7 7.3g\relax }{subfigure.7.3.7}{}}
\newlabel{fig11b}{{7.3h}{86}{Subfigure 7 7.3h}{subfigure.7.3.8}{}}
\newlabel{sub@fig11b}{{(h)}{h}{Subfigure 7 7.3h\relax }{subfigure.7.3.8}{}}
\newlabel{fig11b}{{7.3i}{86}{Subfigure 7 7.3i}{subfigure.7.3.9}{}}
\newlabel{sub@fig11b}{{(i)}{i}{Subfigure 7 7.3i\relax }{subfigure.7.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Accuracy analysis for different training routines.}}{86}{figure.caption.11}}
\newlabel{trainingcomparison}{{7.3}{86}{Accuracy analysis for different training routines}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Routine A, moments}}}{86}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Routine A, final result.}}}{86}{subfigure.3.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Routine A, running time.}}}{86}{subfigure.3.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Routine B,moments.}}}{86}{subfigure.3.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Routine B, final result.}}}{86}{subfigure.3.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Routine B, running time.}}}{86}{subfigure.3.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {Routine C, moments.}}}{86}{subfigure.3.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {Routine C, final result.}}}{86}{subfigure.3.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {Routine C, running time.}}}{86}{subfigure.3.9}}
\newlabel{fig11a}{{7.4a}{87}{Subfigure 7 7.4a}{subfigure.7.4.1}{}}
\newlabel{sub@fig11a}{{(a)}{a}{Subfigure 7 7.4a\relax }{subfigure.7.4.1}{}}
\newlabel{fig11b}{{7.4b}{87}{Subfigure 7 7.4b}{subfigure.7.4.2}{}}
\newlabel{sub@fig11b}{{(b)}{b}{Subfigure 7 7.4b\relax }{subfigure.7.4.2}{}}
\newlabel{fig11b}{{7.4c}{87}{Subfigure 7 7.4c}{subfigure.7.4.3}{}}
\newlabel{sub@fig11b}{{(c)}{c}{Subfigure 7 7.4c\relax }{subfigure.7.4.3}{}}
\newlabel{fig11a}{{7.4d}{87}{Subfigure 7 7.4d}{subfigure.7.4.4}{}}
\newlabel{sub@fig11a}{{(d)}{d}{Subfigure 7 7.4d\relax }{subfigure.7.4.4}{}}
\newlabel{fig11b}{{7.4e}{87}{Subfigure 7 7.4e}{subfigure.7.4.5}{}}
\newlabel{sub@fig11b}{{(e)}{e}{Subfigure 7 7.4e\relax }{subfigure.7.4.5}{}}
\newlabel{fig11b}{{7.4f}{87}{Subfigure 7 7.4f}{subfigure.7.4.6}{}}
\newlabel{sub@fig11b}{{(f)}{f}{Subfigure 7 7.4f\relax }{subfigure.7.4.6}{}}
\newlabel{fig11a}{{7.4g}{87}{Subfigure 7 7.4g}{subfigure.7.4.7}{}}
\newlabel{sub@fig11a}{{(g)}{g}{Subfigure 7 7.4g\relax }{subfigure.7.4.7}{}}
\newlabel{fig11b}{{7.4h}{87}{Subfigure 7 7.4h}{subfigure.7.4.8}{}}
\newlabel{sub@fig11b}{{(h)}{h}{Subfigure 7 7.4h\relax }{subfigure.7.4.8}{}}
\newlabel{fig11b}{{7.4i}{87}{Subfigure 7 7.4i}{subfigure.7.4.9}{}}
\newlabel{sub@fig11b}{{(i)}{i}{Subfigure 7 7.4i\relax }{subfigure.7.4.9}{}}
\newlabel{fig11a}{{7.4j}{87}{Subfigure 7 7.4j}{subfigure.7.4.10}{}}
\newlabel{sub@fig11a}{{(j)}{j}{Subfigure 7 7.4j\relax }{subfigure.7.4.10}{}}
\newlabel{fig11b}{{7.4k}{87}{Subfigure 7 7.4k}{subfigure.7.4.11}{}}
\newlabel{sub@fig11b}{{(k)}{k}{Subfigure 7 7.4k\relax }{subfigure.7.4.11}{}}
\newlabel{fig11b}{{7.4l}{87}{Subfigure 7 7.4l}{subfigure.7.4.12}{}}
\newlabel{sub@fig11b}{{(l)}{l}{Subfigure 7 7.4l\relax }{subfigure.7.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Accuracy analysis for different acquisition function.}}{87}{figure.caption.12}}
\newlabel{acquisition}{{7.4}{87}{Accuracy analysis for different acquisition function}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {US, moments.}}}{87}{subfigure.4.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {US, final result.}}}{87}{subfigure.4.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {US, sampling.}}}{87}{subfigure.4.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {PROP, moments.}}}{87}{subfigure.4.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {PROP, final result.}}}{87}{subfigure.4.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {PROP, sampling.}}}{87}{subfigure.4.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {MMLT, moments.}}}{87}{subfigure.4.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {MMLT, final result.}}}{87}{subfigure.4.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {MMLT, sampling.}}}{87}{subfigure.4.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {MMLT$_P$, moments.}}}{87}{subfigure.4.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {MMLT$_P$, final result.}}}{87}{subfigure.4.11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {MMLT$_P$, sampling.}}}{87}{subfigure.4.12}}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}N-d toy examples}{88}{section.7.2}}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\citation{Acerbi_2018}
\citation{Bilionis_2013}
\newlabel{fig11a}{{7.5a}{90}{Subfigure 7 7.5a}{subfigure.7.5.1}{}}
\newlabel{sub@fig11a}{{(a)}{a}{Subfigure 7 7.5a\relax }{subfigure.7.5.1}{}}
\newlabel{fig11b}{{7.5b}{90}{Subfigure 7 7.5b}{subfigure.7.5.2}{}}
\newlabel{sub@fig11b}{{(b)}{b}{Subfigure 7 7.5b\relax }{subfigure.7.5.2}{}}
\newlabel{fig11a}{{7.5c}{90}{Subfigure 7 7.5c}{subfigure.7.5.3}{}}
\newlabel{sub@fig11a}{{(c)}{c}{Subfigure 7 7.5c\relax }{subfigure.7.5.3}{}}
\newlabel{fig11b}{{7.5d}{90}{Subfigure 7 7.5d}{subfigure.7.5.4}{}}
\newlabel{sub@fig11b}{{(d)}{d}{Subfigure 7 7.5d\relax }{subfigure.7.5.4}{}}
\newlabel{fig11a}{{7.5e}{90}{Subfigure 7 7.5e}{subfigure.7.5.5}{}}
\newlabel{sub@fig11a}{{(e)}{e}{Subfigure 7 7.5e\relax }{subfigure.7.5.5}{}}
\newlabel{fig11b}{{7.5f}{90}{Subfigure 7 7.5f}{subfigure.7.5.6}{}}
\newlabel{sub@fig11b}{{(f)}{f}{Subfigure 7 7.5f\relax }{subfigure.7.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Accuracy analysis for different N-d examples.}}{90}{figure.caption.14}}
\newlabel{ndtoy}{{7.5}{90}{Accuracy analysis for different N-d examples}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Lumpy, means accuracy.}}}{90}{subfigure.5.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Lumpy, covariances accuracy.}}}{90}{subfigure.5.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Cigar, means accuracy.}}}{90}{subfigure.5.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Cigar, covariances accuracy.}}}{90}{subfigure.5.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {Student-t, means accuracy.}}}{90}{subfigure.5.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Student-t, covariances accuracy.}}}{90}{subfigure.5.6}}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces gsKL divergence between true distribution and estimated distribution. The values for VBMC were taken from the graphs in \cite  {Acerbi_2018}.\relax }}{91}{table.caption.13}}
\newlabel{toytable}{{7.1}{91}{gsKL divergence between true distribution and estimated distribution. The values for VBMC were taken from the graphs in \cite {Acerbi_2018}.\relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Contamination source estimation}{91}{section.7.3}}
\newlabel{posteriorsource}{{7.8}{92}{Contamination source estimation}{equation.7.3.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces  Comparison of the true parameter of the problem (first row), the estimated means using BVBMC (second row) and EMCEE (third row), and 70\% highest posterior density interval for BVBMC and EMCEE.\relax }}{93}{table.caption.15}}
\newlabel{sourcetable}{{7.2}{93}{Comparison of the true parameter of the problem (first row), the estimated means using BVBMC (second row) and EMCEE (third row), and 70\% highest posterior density interval for BVBMC and EMCEE.\relax }{table.caption.15}{}}
\citation{Foreman_Mackey_2013}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Checking performance}{94}{section.7.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces KDE plots of estimated marginals with BVBMC. On diagonal.}}{95}{figure.caption.16}}
\newlabel{sourcevbhistogram}{{7.6}{95}{KDE plots of estimated marginals with BVBMC. On diagonal}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces KDE plots of estimated marginals with EMCEE. On diagonal.}}{96}{figure.caption.17}}
\newlabel{sourceemceehistogram}{{7.7}{96}{KDE plots of estimated marginals with EMCEE. On diagonal}{figure.caption.17}{}}
\citation{Rasmussen06}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Future challenges and conclusion}{98}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Reparameterization trick with Gaussian Processes}{98}{section.8.1}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Extending BVBMC to pseudo-marginal likelihoods}{98}{section.8.2}}
\citation{Bliznyuk_2012}
\citation{Marzouk_2007}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Scaling BVBMC to a larger number of evaluations}{99}{section.8.3}}
\bibdata{post-text/referencias}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Conclusion}{100}{section.8.4}}
\bibcite{Beaumont_2003}{1}
\bibcite{Acerbi_2018}{2}
\bibcite{CIS-4647}{3}
\bibcite{Andrieu_2010}{4}
\bibcite{Andrieu_2009}{5}
\bibcite{Arenz_2018}{6}
\bibcite{Asher_2015}{7}
\bibcite{Bassett_2018}{8}
\bibcite{Betancourt_2017}{9}
\@writefile{toc}{\contentsline {chapter}{References}{101}{chapter*.18}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{Bilionis_2013}{10}
\bibcite{Bingham_2018}{11}
\bibcite{Bishop_2007}{12}
\bibcite{Bishop_1997}{13}
\bibcite{Blei_2017}{14}
\bibcite{Bliznyuk_2012}{15}
\bibcite{Booker_1999}{16}
\bibcite{Boyd_2004}{17}
\bibcite{Briol_2015}{18}
\bibcite{Brochu_2010}{19}
\bibcite{Brooks_2011}{20}
\bibcite{Bui_2016}{21}
\bibcite{Chai_2019}{22}
\bibcite{Chatfield_2004}{23}
\bibcite{Conrad_2016}{24}
\bibcite{Cox_1963}{25}
\bibcite{Dudley_2002}{26}
\bibcite{Eckart_1936}{27}
\bibcite{Epanechnikov_1969}{28}
\bibcite{Abadi_2015}{29}
\bibcite{Fearnhead_2012}{30}
\bibcite{Foreman_Mackey_2013}{31}
\bibcite{Fowlkes_2004}{32}
\bibcite{Freund_1997}{33}
\bibcite{Freund_1999}{34}
\bibcite{Friedman_2000}{35}
\bibcite{Friedman_2001}{36}
\bibcite{Gershman_2012}{37}
\bibcite{Geyer_2011}{38}
\bibcite{Ghahramani_2013}{39}
\bibcite{Ghahramani_2015}{40}
\bibcite{Ghahramani_2003}{41}
\bibcite{Gittens_2011}{42}
\bibcite{Goodfellow_2016}{43}
\bibcite{Gunter_2014}{44}
\bibcite{Guo_2016}{45}
\bibcite{Hennig_2012}{46}
\bibcite{Hensman_2012}{47}
\bibcite{Hernandes-Lobato_2015}{48}
\bibcite{Hjort_2010}{49}
\bibcite{Hoffman_2013}{50}
\bibcite{hogben14}{51}
\bibcite{Huber_2008}{52}
\bibcite{Jaakkola_1998}{53}
\bibcite{Jankowiak_2019}{54}
\bibcite{jaynes03}{55}
\bibcite{Jones_2001}{56}
\bibcite{Kanagawa_2019}{57}
\bibcite{Kanagawa_2018}{58}
\bibcite{Kandasamy_2015}{59}
\bibcite{Kingma_2014}{60}
\bibcite{Kingma_2013}{61}
\bibcite{Yingzhen_2016}{62}
\bibcite{Haitao_2018}{63}
\bibcite{Liu_1994}{64}
\bibcite{Locatelo_2018}{65}
\bibcite{MacKay2003}{66}
\bibcite{MacKay_1991}{67}
\bibcite{Marzouk_2007}{68}
\bibcite{Mermin_2004}{69}
\bibcite{Miller_2016}{70}
\bibcite{Mohammed_2017}{71}
\bibcite{Murphy_2012}{72}
\bibcite{Murray_2016}{73}
\bibcite{Neal_1997}{74}
\bibcite{Osborne_2012}{75}
\bibcite{Osborne_2007}{76}
\bibcite{O_Hagan_1991}{77}
\bibcite{OHagan_1992}{78}
\bibcite{Paszke_2017}{79}
\bibcite{Petelin_2014}{80}
\bibcite{Petersen_2012}{81}
\bibcite{Pinheiro_1996}{82}
\bibcite{Pritchard_1999}{83}
\bibcite{Qian_1999}{84}
\bibcite{Candela_2005}{85}
\bibcite{Ranganath_2014}{86}
\bibcite{Rasmussen06}{87}
\bibcite{Rasmussen_2001}{88}
\bibcite{Rasmussen_2003}{89}
\bibcite{Robbins_1951}{90}
\bibcite{Robert_2001}{91}
\bibcite{Robert_2005}{92}
\bibcite{Ruder_2016}{93}
\bibcite{Ruiz_2016}{94}
\bibcite{Salimans_2012}{95}
\bibcite{Salvatier_2016}{96}
\bibcite{Seeger_2003}{97}
\bibcite{Shahriari_2016}{98}
\bibcite{Shawe_Taylor_2004}{99}
\bibcite{Sherlock_2015}{100}
\bibcite{Silverman_1985}{101}
\bibcite{Smith_1995}{102}
\bibcite{Smola_2001}{103}
\bibcite{Snelson_2006}{104}
\bibcite{Snoek_2012}{105}
\bibcite{Stein_1999}{106}
\bibcite{Stuart_2010}{107}
\bibcite{Tarantola_2004}{108}
\bibcite{Theano_2016}{109}
\bibcite{Titsias_2009}{110}
\bibcite{Titsias_2015}{111}
\bibcite{Tran_2016}{112}
\bibcite{Wang_2018}{113}
\bibcite{Wang_2018_2}{114}
\bibcite{Wang_2009}{115}
\bibcite{Williams01usingthe}{116}
\bibcite{wilson2013gaussian}{117}
\bibcite{Wingate_2013}{118}
\bibcite{Zhang_2019}{119}
\bibcite{Tong_Zhang_2003}{120}
\bibstyle{plain}
\citation{Haitao_2018}
\citation{Eckart_1936}
\citation{Williams01usingthe}
\citation{Fowlkes_2004}
\citation{Wang_2009}
\@writefile{toc}{\setbox \@tempboxa \hbox {{{\sffamily  \textbf  {\MakeUppercase  {Appendix} }}}}\ii@chapnumindent \wd \@tempboxa \setbox \@tempboxa \box \voidb@x  \advance \ii@chapnumindent  1.8em\relax  }
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} A}SPARSE GAUSSIAN PROCESSES}{115}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sparsegpchapter}{{A}{115}{SPARSE GAUSSIAN PROCESSES}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Nystrom extension}{115}{section.A.1}}
\citation{Gittens_2011}
\citation{Candela_2005}
\citation{Candela_2005}
\citation{Smola_2001}
\citation{Seeger_2003}
\citation{Snelson_2006}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Prior approximations}{116}{section.A.2}}
\newlabel{GPRalternative}{{A.1}{117}{Prior approximations}{equation.A.2.1}{}}
\newlabel{exactapproxinducing}{{A.5}{117}{Prior approximations}{equation.A.2.5}{}}
\citation{Smola_2001}
\citation{Silverman_1985}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {A.2.0.1}Subset of regressors}{118}{subsubsection.A.2.0.1}}
\citation{Smola_2001}
\citation{Seeger_2003}
\citation{Rasmussen06}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Deterministic Training Conditional}{119}{subsection.A.2.1}}
\citation{Candela_2005}
\citation{Snelson_2006}
\newlabel{dtcprediction}{{A.15}{120}{Deterministic Training Conditional}{equation.A.2.15}{}}
\newlabel{dtcobjective}{{A.16}{120}{Deterministic Training Conditional}{equation.A.2.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}Fully Independent Training Conditional and Fully Independent Conditional}{120}{subsection.A.2.2}}
\citation{Snelson_2006}
\newlabel{fitcpred}{{A.20}{121}{Fully Independent Training Conditional and Fully Independent Conditional}{equation.A.2.20}{}}
\citation{Titsias_2009}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Posterior approximation via variational free energy}{122}{section.A.3}}
\newlabel{gpmarginy}{{A.25}{122}{Posterior approximation via variational free energy}{equation.A.3.25}{}}
\newlabel{qumargin}{{A.27}{122}{Posterior approximation via variational free energy}{equation.A.3.27}{}}
\newlabel{vfeobjective}{{A.29}{123}{Posterior approximation via variational free energy}{equation.A.3.29}{}}
\newlabel{vfeobjective2}{{A.30}{123}{Posterior approximation via variational free energy}{equation.A.3.30}{}}
\citation{Bui_2016}
\newlabel{vfeprediction}{{A.31}{124}{Posterior approximation via variational free energy}{equation.A.3.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Bayesian Monte Carlo with Sparse Gaussian Processes}{124}{subsection.A.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}VBMC and BVBMC with Sparse Gaussian Processes}{125}{subsection.A.3.2}}
\citation{Petersen_2012}
\citation{Candela_2005}
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} B}RELEVANT GAUSSIAN AND MATRIX IDENTITIES}{126}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Matrix inversion lemma}{126}{section.B.1}}
\newlabel{matrixinversionlemma}{{B.1}{126}{Matrix inversion lemma}{equation.B.1.1}{}}
\newlabel{matrixinverselemmalemma}{{B.2}{126}{Matrix inversion lemma}{equation.B.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Product of Gaussian densities}{126}{section.B.2}}
\newlabel{productgaussians}{{B.3}{126}{Product of Gaussian densities}{equation.B.2.3}{}}
\newlabel{margingaussian}{{B.4}{127}{Product of Gaussian densities}{equation.B.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Conditional of a Gaussian density}{127}{section.B.3}}
\newlabel{appendixconditional}{{B.3}{127}{Conditional of a Gaussian density}{section.B.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} C}Alternative derivation of GP predictions}{128}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{alternativegpsection}{{C}{128}{Alternative derivation of GP predictions}{appendix.C}{}}
\newlabel{GPRalternativeAppendix}{{C.1}{128}{Alternative derivation of GP predictions}{equation.C.0.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} D}Spectral mixture kernels and Bayesian Monte Carlo}{130}{appendix.D}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} E}Derivations for VFE}{133}{appendix.E}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {E.1}Maximizaton of variational free energy}{133}{section.E.1}}
\newlabel{vfemaxsection}{{E.1}{133}{Maximizaton of variational free energy}{section.E.1}{}}
\newlabel{vfeobjectivepartial}{{E.1}{133}{Maximizaton of variational free energy}{equation.E.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E.2}Equivalence between VFE and DTC prediction}{134}{section.E.2}}
\newlabel{vfeequipsection}{{E.2}{134}{Equivalence between VFE and DTC prediction}{section.E.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {\MakeUppercase  {Appendix} F}REINFORCE gradient}{135}{appendix.F}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{LastPage}{{}{135}{}{page.135}{}}
\xdef\lastpage@lastpage{135}
\xdef\lastpage@lastpageHy{135}
\gdef\totalpages{149}
